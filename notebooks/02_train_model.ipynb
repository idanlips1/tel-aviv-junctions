{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tel Aviv Junctions - Model Training\n",
        "\n",
        "This notebook trains ML models to predict scooter accidents at junctions.\n",
        "\n",
        "## Overview\n",
        "\n",
        "- Feature engineering for panel data\n",
        "- Panel-aware train/test split (avoid temporal leakage)\n",
        "- Baseline models (Random Forest, XGBoost)\n",
        "- Evaluation and feature importance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error, mean_absolute_error, r2_score,\n",
        "    classification_report, confusion_matrix,\n",
        "    roc_auc_score, roc_curve\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    HAS_XGBOOST = True\n",
        "except ImportError:\n",
        "    print(\"XGBoost not installed. Install with: pip install xgboost\")\n",
        "    HAS_XGBOOST = False\n",
        "\n",
        "from tel_aviv_junctions.panel import load_panel_dataset\n",
        "from tel_aviv_junctions.config import OUTPUT_DIR\n",
        "\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data\n",
        "\n",
        "Load the panel dataset with accident labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "panel_path = Path(OUTPUT_DIR) / \"tel_aviv_junctions_panel.csv\"\n",
        "\n",
        "if not panel_path.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Panel dataset not found at {panel_path}. \"\n",
        "        \"Please run the data extraction pipeline first.\"\n",
        "    )\n",
        "\n",
        "df = load_panel_dataset(str(panel_path))\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "\n",
        "# Check if we have accident labels\n",
        "if 'accident_count' not in df.columns:\n",
        "    print(\"\\n⚠️  Warning: No 'accident_count' column found.\")\n",
        "    print(\"The dataset needs accident labels for supervised learning.\")\n",
        "    print(\"Use join_accidents_temporal() to add them.\")\n",
        "else:\n",
        "    print(f\"\\n✓ Accident labels found\")\n",
        "    print(f\"  Total accidents: {df['accident_count'].sum():,}\")\n",
        "    print(f\"  Junction-years with accidents: {(df['accident_count'] > 0).sum():,}\")\n",
        "\n",
        "display(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering\n",
        "\n",
        "Prepare features for modeling. Handle:\n",
        "- Static vs time-varying features\n",
        "- Categorical encoding\n",
        "- Missing values\n",
        "- Feature selection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_features(df):\n",
        "    \"\"\"Prepare features for ML model.\"\"\"\n",
        "    df = df.copy()\n",
        "    \n",
        "    # Separate target\n",
        "    if 'accident_count' in df.columns:\n",
        "        y = df['accident_count'].copy()\n",
        "    else:\n",
        "        y = None\n",
        "    \n",
        "    # Drop non-feature columns\n",
        "    drop_cols = ['junction_id', 'osm_node_ids', 'cluster_id']\n",
        "    if y is not None:\n",
        "        drop_cols.append('accident_count')\n",
        "    \n",
        "    X = df.drop(columns=[c for c in drop_cols if c in df.columns])\n",
        "    \n",
        "    # Handle categorical features\n",
        "    categorical_cols = ['dominant_surface', 'cycleway_type']\n",
        "    for col in categorical_cols:\n",
        "        if col in X.columns:\n",
        "            # One-hot encode\n",
        "            dummies = pd.get_dummies(X[col], prefix=col, dummy_na=True)\n",
        "            X = pd.concat([X.drop(columns=[col]), dummies], axis=1)\n",
        "    \n",
        "    # Fill missing numeric values with median\n",
        "    numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
        "    for col in numeric_cols:\n",
        "        if X[col].isna().any():\n",
        "            median_val = X[col].median()\n",
        "            X[col] = X[col].fillna(median_val)\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "X, y = prepare_features(df)\n",
        "\n",
        "print(f\"Feature matrix shape: {X.shape}\")\n",
        "print(f\"\\nFeature columns ({len(X.columns)}):\")\n",
        "for i, col in enumerate(X.columns, 1):\n",
        "    print(f\"  {i:2d}. {col}\")\n",
        "\n",
        "if y is not None:\n",
        "    print(f\"\\nTarget distribution:\")\n",
        "    print(y.describe())\n",
        "    print(f\"\\nZero accidents: {(y == 0).sum()} ({(y == 0).mean()*100:.1f}%)\")\n",
        "    print(f\"Non-zero accidents: {(y > 0).sum()} ({(y > 0).mean()*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Panel-Aware Train/Test Split\n",
        "\n",
        "**Important**: For panel data, we should split by time to avoid data leakage.\n",
        "Use earlier years for training and later years for testing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split by year: train on earlier years, test on later years\n",
        "train_years = [2015, 2016, 2017, 2018, 2019, 2020, 2021]\n",
        "test_years = [2022, 2023, 2024]\n",
        "\n",
        "train_mask = df['year'].isin(train_years)\n",
        "test_mask = df['year'].isin(test_years)\n",
        "\n",
        "X_train = X[train_mask].copy()\n",
        "X_test = X[test_mask].copy()\n",
        "y_train = y[train_mask].copy() if y is not None else None\n",
        "y_test = y[test_mask].copy() if y is not None else None\n",
        "\n",
        "print(f\"Training set: {len(X_train):,} rows ({train_years})\")\n",
        "print(f\"Test set: {len(X_test):,} rows ({test_years})\")\n",
        "\n",
        "if y_train is not None:\n",
        "    print(f\"\\nTraining target stats:\")\n",
        "    print(f\"  Mean: {y_train.mean():.2f}\")\n",
        "    print(f\"  Non-zero: {(y_train > 0).sum():,} ({(y_train > 0).mean()*100:.1f}%)\")\n",
        "    \n",
        "    print(f\"\\nTest target stats:\")\n",
        "    print(f\"  Mean: {y_test.mean():.2f}\")\n",
        "    print(f\"  Non-zero: {(y_test > 0).sum():,} ({(y_test > 0).mean()*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 1: Random Forest (Regression)\n",
        "\n",
        "Predict accident count as a continuous value.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if y_train is not None:\n",
        "    # Random Forest Regressor\n",
        "    rf_reg = RandomForestRegressor(\n",
        "        n_estimators=100,\n",
        "        max_depth=15,\n",
        "        min_samples_split=10,\n",
        "        min_samples_leaf=5,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    \n",
        "    print(\"Training Random Forest Regressor...\")\n",
        "    rf_reg.fit(X_train, y_train)\n",
        "    \n",
        "    # Predictions\n",
        "    y_train_pred = rf_reg.predict(X_train)\n",
        "    y_test_pred = rf_reg.predict(X_test)\n",
        "    \n",
        "    # Metrics\n",
        "    print(\"\\nTraining Metrics:\")\n",
        "    print(f\"  RMSE: {np.sqrt(mean_squared_error(y_train, y_train_pred)):.3f}\")\n",
        "    print(f\"  MAE: {mean_absolute_error(y_train, y_train_pred):.3f}\")\n",
        "    print(f\"  R²: {r2_score(y_train, y_train_pred):.3f}\")\n",
        "    \n",
        "    print(\"\\nTest Metrics:\")\n",
        "    print(f\"  RMSE: {np.sqrt(mean_squared_error(y_test, y_test_pred)):.3f}\")\n",
        "    print(f\"  MAE: {mean_absolute_error(y_test, y_test_pred):.3f}\")\n",
        "    print(f\"  R²: {r2_score(y_test, y_test_pred):.3f}\")\n",
        "    \n",
        "    # Feature importance\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': X_train.columns,\n",
        "        'importance': rf_reg.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    \n",
        "    print(\"\\nTop 10 Most Important Features:\")\n",
        "    display(feature_importance.head(10))\n",
        "    \n",
        "    # Plot feature importance\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    top_features = feature_importance.head(15)\n",
        "    plt.barh(range(len(top_features)), top_features['importance'])\n",
        "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
        "    plt.xlabel('Importance')\n",
        "    plt.title('Top 15 Feature Importances (Random Forest)')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No target variable available for training\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 2: Random Forest (Classification)\n",
        "\n",
        "Predict whether a junction-year will have accidents (binary classification).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if y_train is not None:\n",
        "    # Convert to binary: has accidents (1) or not (0)\n",
        "    y_train_binary = (y_train > 0).astype(int)\n",
        "    y_test_binary = (y_test > 0).astype(int)\n",
        "    \n",
        "    rf_clf = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=15,\n",
        "        min_samples_split=10,\n",
        "        min_samples_leaf=5,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        class_weight='balanced'  # Handle class imbalance\n",
        "    )\n",
        "    \n",
        "    print(\"Training Random Forest Classifier...\")\n",
        "    rf_clf.fit(X_train, y_train_binary)\n",
        "    \n",
        "    # Predictions\n",
        "    y_train_pred_binary = rf_clf.predict(X_train)\n",
        "    y_test_pred_binary = rf_clf.predict(X_test)\n",
        "    y_test_proba = rf_clf.predict_proba(X_test)[:, 1]\n",
        "    \n",
        "    # Metrics\n",
        "    print(\"\\nTraining Metrics:\")\n",
        "    print(classification_report(y_train_binary, y_train_pred_binary))\n",
        "    \n",
        "    print(\"\\nTest Metrics:\")\n",
        "    print(classification_report(y_test_binary, y_test_pred_binary))\n",
        "    \n",
        "    # ROC AUC\n",
        "    if len(np.unique(y_test_binary)) > 1:\n",
        "        auc = roc_auc_score(y_test_binary, y_test_proba)\n",
        "        print(f\"\\nTest ROC AUC: {auc:.3f}\")\n",
        "        \n",
        "        # Plot ROC curve\n",
        "        fpr, tpr, _ = roc_curve(y_test_binary, y_test_proba)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.3f})')\n",
        "        plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('ROC Curve - Accident Prediction')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"No target variable available for training\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if HAS_XGBOOST and y_train is not None:\n",
        "    # XGBoost Regressor\n",
        "    xgb_reg = xgb.XGBRegressor(\n",
        "        n_estimators=100,\n",
        "        max_depth=6,\n",
        "        learning_rate=0.1,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    \n",
        "    print(\"Training XGBoost Regressor...\")\n",
        "    xgb_reg.fit(X_train, y_train)\n",
        "    \n",
        "    # Predictions\n",
        "    y_test_pred_xgb = xgb_reg.predict(X_test)\n",
        "    \n",
        "    # Metrics\n",
        "    print(\"\\nTest Metrics:\")\n",
        "    print(f\"  RMSE: {np.sqrt(mean_squared_error(y_test, y_test_pred_xgb)):.3f}\")\n",
        "    print(f\"  MAE: {mean_absolute_error(y_test, y_test_pred_xgb):.3f}\")\n",
        "    print(f\"  R²: {r2_score(y_test, y_test_pred_xgb):.3f}\")\n",
        "    \n",
        "    # Feature importance\n",
        "    xgb_importance = pd.DataFrame({\n",
        "        'feature': X_train.columns,\n",
        "        'importance': xgb_reg.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    \n",
        "    print(\"\\nTop 10 Most Important Features (XGBoost):\")\n",
        "    display(xgb_importance.head(10))\n",
        "else:\n",
        "    if not HAS_XGBOOST:\n",
        "        print(\"XGBoost not available. Install with: pip install xgboost\")\n",
        "    else:\n",
        "        print(\"No target variable available for training\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Comparison\n",
        "\n",
        "Compare predictions from different models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if y_test is not None:\n",
        "    comparison = pd.DataFrame({\n",
        "        'actual': y_test.values,\n",
        "        'rf_regression': y_test_pred,\n",
        "    })\n",
        "    \n",
        "    if HAS_XGBOOST:\n",
        "        comparison['xgb_regression'] = y_test_pred_xgb\n",
        "    \n",
        "    # Scatter plots\n",
        "    n_models = 2 if HAS_XGBOOST else 1\n",
        "    fig, axes = plt.subplots(1, n_models, figsize=(6*n_models, 5))\n",
        "    if n_models == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    axes[0].scatter(comparison['actual'], comparison['rf_regression'], alpha=0.3)\n",
        "    axes[0].plot([0, comparison['actual'].max()], [0, comparison['actual'].max()], 'r--')\n",
        "    axes[0].set_xlabel('Actual Accidents')\n",
        "    axes[0].set_ylabel('Predicted Accidents')\n",
        "    axes[0].set_title('Random Forest')\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    if HAS_XGBOOST:\n",
        "        axes[1].scatter(comparison['actual'], comparison['xgb_regression'], alpha=0.3)\n",
        "        axes[1].plot([0, comparison['actual'].max()], [0, comparison['actual'].max()], 'r--')\n",
        "        axes[1].set_xlabel('Actual Accidents')\n",
        "        axes[1].set_ylabel('Predicted Accidents')\n",
        "        axes[1].set_title('XGBoost')\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\nPrediction Statistics:\")\n",
        "    display(comparison.describe())\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
